#net: "models/bvlc_alexnet/train_val.prototxt"
train_net: "./proto/alexnet_ind_finetuning_train.prototxt"
# test_net: "we don't use testing on the fly"
#test_iter: 1000
#test_interval: 1000
#test_interval: 0
#base_lr: 0.01
base_lr: 0.0001
#base_lr: 0.001 # would fail for vanilla alexnet finetuning
lr_policy: "step"
gamma: 0.1
#stepsize: 100000
stepsize: 10000
#stepsize: 3000
display: 20
#max_iter: 450000
max_iter: 20000
#max_iter: 9000
momentum: 0.9
weight_decay: 0.0005
#snapshot: 10000
snapshot: 5000
#snapshot: 1000
snapshot_prefix: "snapshot/caffe_alexnet_finetuning"
solver_mode: GPU
#device_id: 1
device_id: 0
